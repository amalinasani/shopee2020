{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAABnCAYAAAC6lX9uAAAOd0lEQVR4Ae2djXHcOgyE3UJqSAvpISWkhrSQDtJBOkgFriANpIF0kB785vO89cAMJVEi9MdbztxQPyQILMAVyJPPTy8uRsAIGIGbIPB0Ez2tphEwAkbgxYTlIDACRuA2CJiwbuMqK2oEjIAJyzFgBIzAbRAwYd3GVVbUCBgBE5ZjwAgYgdsgYMK6jausqBEwAiYsx4ARMAK3QcCEdRtX3VfRz58/vzw9Pb1+fv78+c4QXad2MQJLCDhKlhDy/W4E/v79+0pWHz58eIG8Ynl+fn699/v373jZx0agioAJqwqLL2YjQAb17du3V3L68+fPm3gI6+PHj2/nPjACcwiYsObQ8b0UBH79+vXy6dOnF7IoiOv79+9vcjn++vXr27kPjMAcAiasOXR8LwWBSEpkUzGjYolY7mulDGohQyJgwhrSrdcyKpLSjx8/XrMssi4KGZf3r67lrytrY8K6sncG0Q1S0r4VNecsAyEtNuJdjEArAiasVqTcbhMCkFJcAiLky5cvr0TFUpFjFyPQioAJqxUpt9uEAKQ09SoD2RX3XYxAKwImrFak3G4TAnw7WPsWELJiaai9rE3C3enhEDBhPZzLjzOY5R6kxKfMpPRO1nHaeKQREDBhjeBF22AEHgQBE9aDONpmGoEREDBhjeDFDht4aZP9JL120CHKXY3A7giYsHaH+JoDsNnNhrj2mK6ppbUyAu8RMGG9x2P4MzIpNsN5Nypuig9vuA0cAgET1hBubDeCVwziN3bOsNqxc8vzETBhne+DUzXYSlgsKdX3qPpUoDz4JRAwYV3CDecpIbJZq4F+Kkb9j6jX6uj24yFgwhrPp6ssEtGs6vR/Y5aW6k/NJj6/LppV9MsOGiNLruXcFwET1n19l6J5Lxnwd4KSQV37M5weRSMp9shx3zEQMGGN4cfNVohstgogo9LfBUpW5g/y6ffgke1iBBwFDx4DIpkeGMoNeAgs80f5lMX16Oi+YyBgwhrDj5utyCAsBi/3mzL3s7Qs3GykOw6DgAlrGFduMySLsBg9voiK3Oz9rG0WutdICJiwRvLmBlsyCYv9Jt6gl0zqzP2sDea5y2AImLAGc+hac0QuWa8jlO9nZe9nrbXP7cdCwIQ1lj9XWRP3neKf66wSUmkc5UKImftZleF86YEQMGE9kLMxtcyAlGGpzsqI2L+STOo997PiOJnHDxYatzDXhHULN91PSZaY8edrIJK99rMySSrKuh/q42tswhrfx6dZSDYXXyrNyt5KgyLJZB6X4+xxzjtsfLvKZ5TCFy9k1Hv8KKQJa5QouagdZFWRRPbYz4ryM4/3hpR/xAGJs3+Y9aXH3jq3yIeoICxsy86qTVgtHnCbLgT23s/KJKkoq8vohc68vb9Xxrkw9GG39bDK/ELHhHWY+x53oL33syLJZB7v5TH9izOWg6MX/ZXC8/NziqkmrBQYLWQJgT33szJJKspasmnLfZZLjFH+N+wtsu7Qh4cVmST7WhnFhJWBomU0IcBTNhJC1n5WlJl53GTUykZaHmdlHCuHP6W5MsqM/axDCQu2xWHxzzdgX542tfSY9qSU8etx2gNAWdQ2yqZfKRfQ1CZOGDIAjcMYtaJvdLjPxKDOXJ/XxhztmoJXxEI89BbJyq5resUNZcbTJNR1rs3FBff4zBXITLEYY5Q+xKniN4v0NC+Fn2ySjsoKdR8d1hTa0zfjm9BDCQvwcZZIJAJVgiTH0F6OkeFlkHOddjhSsgFZTuc+BXJhwjCuJg7tkS9nUNfSdT0ZkUF/PgocyV/jRLVFXhx7zbFk3K2WX2Sr/LvVDsnJrkt98Dm6EzMcMx6xgv+ZjMRcjAvFouRwrj66VtbIQCZyFBv85QCFe8S57KRNRiG2mX+yCfmlbM0Rxt9SpPOWvrHPYYQlZ5XZkUDCGSpcgwwApyQDDJcDaU9b2tXa4gTalwRHPxEWjhDRaVwCJRaRVUmqBBbyy8CMfX38LwLlxCvx/rfH/BVNhux6blTFLQQmglF7EU0Z67reai84YRPyKYzFh7H3KhAvY5YPEc3fVt1L/bLmyuGEBTksAS4yaQFHZFIGB4AJZDk8gigA0ackxdhuSobIDaJcsifKO/I4awLvobP+3hD84sNqy1hZdpZy5nRRXNT0FzGVcafrLXGtsfXgJr73JivGnNJR/trqK803cOsphxEWSgI4QaGMZkpxgoB2LeDMtVWGVQYO4yo4Y7ZW00dPHAFNTR8FUpl11WScdU029tbZ+kPw8lsGfr32TfWfs1sTu/agnLqn69StRQ/kFrKiDZ+eIiIu5wzxXrOVa+C39NC+JWFhlAgAIzkuDRVgLcCrLWDWisAsgV7qF2WVwYxe6A1plbrHfj6eRkDBC44ZpfRR1vmcborjWnaue+XDcAthremD3bXtjzk7aveQE+cUDxUeMLV4x5exbU0e1+Rz5l5POTTDkqIozcQHGAyJRQ4qSSa20TEBUZOh+wDJ/XI9rjGWnCtiK3WU/IxauqDn2k/G+EfLkM/wTW0CbNFnLW6t7ed0YQLzqRVlj+UKQb6mbimQoWJ4KVZb5LW20dxUe3Ro1Vl9yvrWhIUxBKscG41b49S5tiIbwC6LnoBLyxHJ2JOwSt1GPmcCiizANqtIZnY9pZ/sqMUFMYUetXuK15aHMWMwP5TdtKw4pvRde13LUHyEzhljiwR7/X5IhgVB1MhBRkRA5fCaUwEyZkscExzIL4sYPbZXGxFl+QTUfdXcR37NYRAuYyzJkKxHr8FL/mYSZJZsopK8KR0VoyUpYSMPSOKrFhdLD0DuI1NkpaxKsVyTiY66j961wvXag7vWlmvKgpmD9K2RjMh36n4pm3Z8eku/hAYNcCCA4QgKjo2gRBHcoz0ftaeGlPhwPxZNAoGKU2kHODWSRBb3Wh2oYEBfCuMjF/2yJ160a7RjPbVr5N9rqyZDdj2ll2yJMUr8YRvXFIu1/txHz1rRnOB+xEnXiTfij5gsyYv2XK8V4VK7V7uG/upTSxzUR4Sm86la8mqJxVSfqet15KZab7gOwBimiS8gAFgkUIqFVGJ72tbIh37IJ4AUCNQAMxU0ejrq6VWOXZ7X5NNXZFq29/m/CCgTxjflRPu39foriqnsekoTHnaMBYHoGNuIiyX7aEPfWuavrIXYJ+5UOGYO0I+6FtuMP0Uu9Gt9QDMm42ks6VCrmWfos1REbFNzeKl/vL87YcXBfHwuAgp6gpFPbXLFBwVtahNrjRWMwWTKkLVm3L3aajKD05YCHmCxtX9tTK0aar7Sw2LNagCCwWdLD+U5kpSe4EW7NYSpvrXahFVDZdBrBI8yAiZNLcOljYgt44koAmzNaK8OvQhgKptp0V8ZR41gWvqXbbRkxHdlAX/8WbtXtuVcK5Al38+RZJSbbasJK6L7AMcEsJYlU+k8bTKeiFriIKt1wlzdBbJpaUIv2QH2LVnMkhzuTy3NIBV8OYc9y0sRmmxrycbmSFI6i/x6yF2yVJuwhMSD1FqaKdOqLQu517tBqo1WxltaWtwJeghAGPbqzYMD0oIg5khlaRwIR8S01m8iHmzi05oJK3NCN/rEOOJYD8VeYi9tN2GViAx8rjSegFLAlctCJg6BW15fAwsyRIgtT+s1ss9uq4mNfRlLOogdkmklipr9yowgrbUPB8UBpLfGHtpqb6rsh6ySxGp6b7lmwtqC2k37QEIEGYUgY/IRXLHo+trAjzKYgMhmArkYgUwETFiZaF5cFkQSSQTyglhiOq+n9VZTtG+B7J5lztbx3W9sBExYY/v3nXUsY+ISTfsMcfkHoUVSeydg4YSsTCRYLhMWuvq2EWhCwITVBNP9G5FFkU3Flw61/IvLQtpEUltjOXLon/mtEONrX20rka6xwW2vjYAJ69r+SdNOS7VymaaMCELTN3tbsqO4eVuO0WuEiDWbCHv1cv/jETBhHY/5KSOy/IuZlJSIy0KWhmRIawlHREffns166VTWIsOtmV8pz+f3RcCEdV/frdIcsoKcyqLsRfdrpFb2ieeQm7K0uBcW2/Qej/qKRC8uj9jfhPUAXodUyH6mCEWEAzHUSG0Ooj1fYWCZqgxwTv85/XxvLARMWGP5s2qNsqi44R4bRlJY82aylpCQyRGfKf2jLT4eGwET1tj+fd2P4tu1uQxFhEab1j0o2h1BUnEME9bgwdpgngmrAaQ7NxFZaeJPTXqWhXxai5aCkntEPaV7q85ud38ETFj396EtMAIPg4AJ62FcbUONwP0RMGHd34e2wAg8DAImrIdx9b6G8v7W2ne49tXI0kdEwIQ1oldPsIlN97XvcE2pyZvtejcMEmz95nJKnq+Pg4AJaxxfDmGJyIqXRnnhlW8jIS/OXYyACcsxcBkEICUytfhGvt738h8+X8ZNpypiwjoV/vsPHt/z6rVGvyhRvm8FifmnZXrRHaO/CWsMP55qBftMGYSiXzstCQv5/J2jixEwYTkGuhFgj6m2ZGt5+z3+ZMwUYSmL61bUAm6PgAnr9i481wDtMfH3iL1ljrD8ykQvumP0N2GN4cfTrNAvNqz90b+awpJVLgnJ4DKWnLUxfe1eCJiw7uWvy2nLawdT2c/aJaGytbi8rH1zeDkQrNBhCJiwDoN6zIG04a53pnqtJJMio4K8JJPzjAyuVzf3Px8BE9b5Pri1Btp3gmggmd4CMcUfFCSDy5Dbq5f7XwMBE9Y1/GAtjIARaEDAhNUAkpsYASNwDQRMWNfwg7UwAkagAQETVgNIbmIEjMA1EDBhXcMP1sIIGIEGBExYDSC5iREwAtdAwIR1DT9YCyNgBBoQMGE1gOQmRsAIXAMBE9Y1/GAtjIARaEDAhNUAkpsYASNwDQRMWNfwg7UwAkagAQETVgNIbmIEjMA1EDBhXcMP1sIIGIEGBExYDSC5iREwAtdAwIR1DT9YCyNgBBoQMGE1gOQmRsAIXAOB/wD4jHeyaS8rOgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Detection Workbook\n",
    "\n",
    "## Task\n",
    "\n",
    "In this competition, a multiple image classification model needs to be built. There are ~100k images within 42 different categories, including essential medical tools like masks, protective suits and thermometers, home & living products like air-conditioner and fashion products like T-shirts, rings, etc. For the data security purpose the category names will be desensitized. The evaluation metrics is top-1 accuracy.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Where\n",
    "- N is number of test samples.\n",
    "- xi is the predicted category for i th test sample.\n",
    "- yi is the ground truth for i th test sample.\n",
    "- p(xi,yi) is calculated as 1 if xi=yi and 0 otherwise.\n",
    "A higher score is better. In your practice you need to find a proper threshold to predict category name(string) instead of probabilities.\n",
    "\n",
    "Submission File\n",
    "Submission file format should be `csv` file only. And for each `filename` in the test dataset, you must predict only one proper category name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Steps\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "Since the data was from real word use cases, inspection needed to be done to ensure that the data is free from noise and losses. As such, typical pre-processing techniques would be use to de-noise the images dataset. A candidate for this would be to apply Gaussian smoothing to the image dataset.\n",
    "\n",
    "Libraries for such functions would be OpenCV.\n",
    "\n",
    "Quick inspection of the image dataset shows that the images are not in the same sizes, thus preprocessing has to be done to resize the images into a standardise size format. \n",
    "\n",
    "The following article outlines how we can choose the right image size for our image classification model.\n",
    "https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20\n",
    "\n",
    "Ideally, from this we can obtained a processed dataset from where a image classification model can be built from. In this case, we would be using a convolutional neural network to be trained on the dataset for prediction on the test dataset.\n",
    "\n",
    "Image generator idea in keras & tensorflow could help with loading such large datasets which cannot fit in local memory.\n",
    "https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in raw test and training CSVs\n",
    "trainDF = pd.read_csv(\"train.csv\")\n",
    "testDF = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.sort_values(by=[\"category\", 'filename'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55380</th>\n",
       "      <td>00b32bd5ba9cdd7c2f11e3975b3e54fa.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54316</th>\n",
       "      <td>00df3dd83ad6845e6fdfe675d755e17f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55035</th>\n",
       "      <td>00df7aa7afaa7c512b9a317adb0aae24.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53410</th>\n",
       "      <td>00e6066eb828dcbe1755a4dabe189c06.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54273</th>\n",
       "      <td>012c3848585c70f971a1621bae6c8410.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  category\n",
       "55380  00b32bd5ba9cdd7c2f11e3975b3e54fa.jpg         0\n",
       "54316  00df3dd83ad6845e6fdfe675d755e17f.jpg         0\n",
       "55035  00df7aa7afaa7c512b9a317adb0aae24.jpg         0\n",
       "53410  00e6066eb828dcbe1755a4dabe189c06.jpg         0\n",
       "54273  012c3848585c70f971a1621bae6c8410.jpg         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths to image data\n",
    "DATADIR = \"train//train\"\n",
    "CATEGORIES_INT = trainDF['category'].unique().tolist()\n",
    "CATEGORIES = [\"{:02d}\".format((i)) for i in CATEGORIES_INT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "# Reading in image data\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to classifier directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                training_data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        break\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
